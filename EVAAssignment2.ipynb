{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVAAssignment2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhakarmlal/Project1/blob/master/EVAAssignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "# ***Assignement2 -EVA***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urpq_I5ESGMR",
        "colab_type": "text"
      },
      "source": [
        "## **Not an ideal network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNCkFm5SSowX",
        "colab_type": "text"
      },
      "source": [
        "####  Install Keras using pip install and import keras library required for Convolution and building Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpzoKupSTXZP",
        "colab_type": "text"
      },
      "source": [
        "#### Import other packages e.g 'numpy' and 'np_utils' for numeric operations,'Sequential' to build a sequential network,'Convolution2D' for  2D convolutions,'mnist'  for downloading mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGDbIBioURKz",
        "colab_type": "text"
      },
      "source": [
        "#### Split Mnist dataset into  test and train using mnist.load_data() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ9pfqhEUdlF",
        "colab_type": "text"
      },
      "source": [
        "#### Visual first element of the train dataset using matplotlib library used for visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "e7335216-e740-4ed7-de73-5c4640f0c2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcfcaa30e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARNkN_DeVInm",
        "colab_type": "text"
      },
      "source": [
        "####  We need to unroll  the width and hieght of the  images to  28 * 28 frame  for both test and train dataset using reshape() function.This would be required since we would like to work on a  input vector 784(28*28) for our Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkHKJaZYb_CL",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the pixel value distribution for 1st Element of the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3hHKvCxaMnF",
        "colab_type": "code",
        "outputId": "df23516a-fe7e-448d-8c85-0936d236a2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.subplot(2,1,1)\n",
        "plt.hist(X_train[0].reshape(784))\n",
        "plt.title(\"Pixel Value Distribution\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Pixel Value Distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAACSCAYAAABLwAHLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r2Ri3ascKnB",
        "colab_type": "text"
      },
      "source": [
        "#### Looking at the graph above the pixel value distribution values ranges from 0 to 255 .The background majority close to 0(hence around 600 0's in the above plot) and the values which are close to  255 represents the actual digit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfjHf_h-dWZ2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4lK5KbwdYjV",
        "colab_type": "text"
      },
      "source": [
        " ####  Reshape our inputs to a single vector vector and normalize the pixel values to lie between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr9RxsT2ecas",
        "colab_type": "text"
      },
      "source": [
        "#### Normalizing the input data helps to speed up the training. Also, it reduces the chance of getting stuck in local optima, since we're using stochastic gradient descent to find the optimal weights for the network.As explained earlier the X_train value after normalizing would  be between  0 and 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFsQpjzUgo9S",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty0fRqiIgpGq",
        "colab_type": "text"
      },
      "source": [
        "####  Check the values of y_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "fd8d21e1-06e8-40d0-dcd4-2a73cd9f53f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG3_cwutg5zI",
        "colab_type": "text"
      },
      "source": [
        "###   One Hot Encoding\n",
        "#### Convert both training and testing labels into one-hot vectors.Use np_utils.to_categorical to convert 1-dimensional class to 10-dimensional classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KScudZ8vhcqc",
        "colab_type": "text"
      },
      "source": [
        "#### Check the values of Y_train values after the One-Hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "d031933b-233b-4ef2-f8dd-2a424d44ddea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ocLM32ch98D",
        "colab_type": "text"
      },
      "source": [
        "## Build the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTVUeBtpiGFH",
        "colab_type": "text"
      },
      "source": [
        "#### From keras.layers import Activation and MaxPooling2D for building the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYcH25tOiEys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7UlCHkciofy",
        "colab_type": "text"
      },
      "source": [
        "#### Define sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqbELLCdiwQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WvJ5q6oi3x6",
        "colab_type": "text"
      },
      "source": [
        "### First Layer\n",
        "\n",
        "#### Perform 3 * 3 convolution  on the input image of size 28 * 28 i.e perform convolution using  3*3 filter on 28*28 image\n",
        "\n",
        "#### Take 32 3*3  filters  in the 1st layer \n",
        "\n",
        "\n",
        "#### The input channel dimension is: 28 *  28\n",
        "#### The receptive field for the 1st Layer is :3\n",
        "\n",
        "\n",
        "#### The no of input channels for the 1st Layer is :1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN2rpIDLkvZW",
        "colab_type": "code",
        "outputId": "6d2a2335-2e77-4c2d-b408-d858acda2659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyJ8Zvptk8xA",
        "colab_type": "text"
      },
      "source": [
        "###Second Layer\n",
        "\n",
        "####Perform 3 * 3 convolution on the  32 channels  using 3 * 3 filter.\n",
        "####Take 64 3*3 filters\n",
        "\n",
        "\n",
        "#### The input channel dimension is      : 26 *  26\n",
        "####The receptive field for the 2nd Layer is     :5\n",
        "\n",
        "####The  no of input channels for the 2nd Layer is :32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ihyfKmSm9rz",
        "colab_type": "code",
        "outputId": "69447c35-3f9f-4953-ef92-4f24016f4a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.add(Convolution2D(64, 3, 3, activation='relu'))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Iz2Zb2nbTV",
        "colab_type": "text"
      },
      "source": [
        "###3rd  Layer\n",
        "\n",
        "####Perform 3 * 3 convolution on the  64 channels  using 3 * 3 filter.\n",
        "####Take 128 3*3 filters\n",
        "\n",
        "\n",
        "#### The input channel dimension  for 3rd layer is : 24*24\n",
        "\n",
        "####The receptive field for the 3rd  Layer is :7\n",
        "\n",
        "####The no of input channels for the 3rd Layer is :64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9BgHNhyndnq",
        "colab_type": "code",
        "outputId": "d12fa09e-a8ad-467d-9307-bba63ac63117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.add(Convolution2D(128, 3, 3, activation='relu'))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYIA97LqnfnK",
        "colab_type": "text"
      },
      "source": [
        "#### Perform max pooling which would reduce the size of the image from  22 * 22  to  11 * 11 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A57nWLl5noO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDy7nBDgnpPN",
        "colab_type": "text"
      },
      "source": [
        "###4th  Layer\n",
        "\n",
        "#### Perform 3 * 3 convolution on the 128 channels using 3 * 3 filter.\n",
        "\n",
        "#### Take 256 3*3 filters\n",
        "\n",
        "#### The input channel dimension for 4th layer is : 11*11\n",
        "\n",
        "#### The receptive field for the 4th Layer is :14\n",
        "\n",
        "#### The no of  input channels for the 4th  Layer is :128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FORZvgR9nqlI",
        "colab_type": "code",
        "outputId": "52f707c7-8853-4b73-80f5-59a66144fd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.add(Convolution2D(256, 3, 3, activation='relu'))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4i7rKLinrHi",
        "colab_type": "text"
      },
      "source": [
        "###5th  Layer\n",
        "\n",
        "#### Perform 3 * 3 convolution on the 256 channels using 3 * 3 filter.\n",
        "\n",
        "#### Take 512 3*3 filters\n",
        "\n",
        "#### The input channel dimension for 5th layer is : 9*9\n",
        "\n",
        "#### The receptive field for the 5th Layer is :16\n",
        "\n",
        "#### The no of input channels for the 5th  Layer is :128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCJ4pwx7nsyy",
        "colab_type": "code",
        "outputId": "e0c3ac2c-9a49-41d7-8f9e-cc20b063600c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.add(Convolution2D(512, 3, 3, activation='relu'))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LxLvfwxntov",
        "colab_type": "text"
      },
      "source": [
        "###6th  Layer\n",
        "\n",
        "#### Perform 3 * 3 convolution on the 512 channels using 3 * 3 filter.\n",
        "\n",
        "#### Take 1024 3*3 filters\n",
        "\n",
        "#### The input channel dimension for 6th layer is : 7 * 7\n",
        "\n",
        "#### The receptive field for the 6th Layer is :18\n",
        "\n",
        "#### The no of input channels for the 6th  Layer is :512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVwnclCBnvLO",
        "colab_type": "code",
        "outputId": "635a7ce4-80ec-4564-f7f5-810319fdf3fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDeQu4wdnwQg",
        "colab_type": "text"
      },
      "source": [
        "###7th  Layer\n",
        "\n",
        "#### Perform 3 * 3 convolution on the 1024 channels using 3 * 3 filter.\n",
        "\n",
        "#### Take 2048 3*3 filters\n",
        "\n",
        "#### The input channel dimension for 7th layer is : 5 * 5\n",
        "\n",
        "#### The receptive field for the 7th Layer is :20\n",
        "\n",
        "#### The no of input channels for the 7th  Layer is :1024"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_XukhdJn0b7",
        "colab_type": "code",
        "outputId": "5042da28-dc54-494e-dad3-91b2b506dc13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IizZGJ3iormX",
        "colab_type": "text"
      },
      "source": [
        "###8th  Layer\n",
        "\n",
        "#### Perform 3 * 3 convolution on the 2048 channels using 3 * 3 filter.\n",
        "\n",
        "#### Take 10 3*3 filters\n",
        "\n",
        "#### The input channel dimension for 8th layer is : 3 * 3\n",
        "\n",
        "#### The receptive field for the 8th Layer is :22\n",
        "\n",
        "#### The no of input channels for the 8th  Layer is :2048"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl2j5E8Vn1nL",
        "colab_type": "code",
        "outputId": "1c54e3d7-463e-44d7-8ed4-bd80ad73f2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model.add(Convolution2D(10, 3, 3, activation='relu'))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65oRUYr8-Pvm",
        "colab_type": "text"
      },
      "source": [
        "#### The receptive field after the above 3 * 3 convolution would be  24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ4DZuuTo6u2",
        "colab_type": "text"
      },
      "source": [
        "#### Flatten the 10 channels  which is the output of  8th Layer  for the actual output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MW9OxFdPo97x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGdPNRJwpDSV",
        "colab_type": "text"
      },
      "source": [
        "####  Summarize  the model  using model.summary().\n",
        "#### It shows each layer's details along with the number of parameters used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1IiQ8JHpENs",
        "colab_type": "code",
        "outputId": "57899fcb-8ece-470a-e6a0-8af8382716b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "#model = Sequential() \n",
        "#model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "#model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "#model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "#model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "#model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "#model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "#model.add(Convolution2D(10, 3, 3, activation='relu'))\n",
        "\n",
        "#model.add(Flatten())\n",
        "#model.add(Activation('softmax'))\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILIp2zlZzJ5q",
        "colab_type": "text"
      },
      "source": [
        "#### Compile the model.Use categorical_crossentropy as the loss function and adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzf9Ey7lzW4j",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model for 10 epochs with a batch size of 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "1f2367e7-a879-43fb-ab91-145968b1cb43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 118s 2ms/step - loss: 2.3027 - acc: 0.0989\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 2.3026 - acc: 0.0987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcfcb5c75f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp8YlkPCz9UP",
        "colab_type": "text"
      },
      "source": [
        "#### Calculate the score of the *model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMqOqHUxzhbg",
        "colab_type": "text"
      },
      "source": [
        "#### Print the score of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "outputId": "60bb24ff-7201-4cc6-c6ba-b4c019a71dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3025851249694824, 0.098]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M__S65L3By7",
        "colab_type": "text"
      },
      "source": [
        "#### Find the predicted values using model.predict() on the test dataset(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0-CHlI2zyQ0",
        "colab_type": "text"
      },
      "source": [
        "#### Print  y_pred(One hot encoded) values and the actual y value for the 1st 10 records in the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "outputId": "5278b058-4908-467d-9680-e9a67f445fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            " [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vLmAP190B_8",
        "colab_type": "text"
      },
      "source": [
        "## Whats Wrong with the Model?\n",
        "\n",
        "#### 1.The Model has reached till the  receptive field  of 24 but the actual image size is 28.Hence we can't achieve the optimal performance since we we haven't read the complete image.\n",
        "\n",
        "#### 2.Its not required to do a max pooling for a small 28*28 image.We can do the same for a larger image.In case we do max pooling for a small image there would be loss of information which would lead to reduction in performance.\n",
        "\n",
        "#### 3.There activation function may not be used for the penultimate layer where we have almost very close to the image identification.Use of relu may lead to loss of information\n",
        "\n",
        "\n",
        "#### 4.More number of filters would mean more processing which may not be feasible with commodity hardware.We may not need more number of filters for the later layers where we are close to image identification and hence can reduce the number of filters for the later layers .\n",
        "\n",
        "####In case we want more number of filters in the later layers we can run that only on high end configuration machine which would be expensive\n",
        "\n"
      ]
    }
  ]
}