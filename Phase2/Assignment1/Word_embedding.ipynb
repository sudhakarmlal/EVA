{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhakarmlal/EVA/blob/master/Phase2/Assignment1/Word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEaiPXGyrJA8",
        "colab_type": "text"
      },
      "source": [
        "# Word-embeddings\n",
        "Name : K Sudhakar Reddy\n",
        "\n",
        "Background :\n",
        "This Assignment we will be using the most popular method Word Embedding to find out how it works \n",
        "\n",
        "Deep Learning for NLP is pattern recognition applied to words, sentences, and paragraphs, in much the same way that computer vision is pattern recognition to pixels.Like all other neural networks, deep-learning models don't take as input raw text: they only work with numeric tensors. Vectorizing text is the process of transforming text into numeric tensors. \n",
        "\n",
        "Requirements :\n",
        "We will use the IMDB database and Glove model to create the word embedding\n",
        "\n",
        "Environment:\n",
        "Development - Colab GPU , Jupyter Notebook Repository : Github\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGyoFkhgyO2G",
        "colab_type": "text"
      },
      "source": [
        "# Import all Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxJ5t5iBrLZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2yD1hQuyYrj",
        "colab_type": "text"
      },
      "source": [
        "# Request to get the IMDB data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeeFYYwNLOgo",
        "colab_type": "code",
        "outputId": "66450971-47d5-47a5-d350-5f515b906434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!wget --no-check-certificate http://mng.bz/0tIo\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-23 14:24:06--  http://mng.bz/0tIo\n",
            "Resolving mng.bz (mng.bz)... 35.166.24.88\n",
            "Connecting to mng.bz (mng.bz)|35.166.24.88|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://mng.bz/0tIo [following]\n",
            "--2020-01-23 14:24:11--  https://mng.bz/0tIo\n",
            "Connecting to mng.bz (mng.bz)|35.166.24.88|:443... connected.\n",
            "WARNING: cannot verify mng.bz's certificate, issued by ‘CN=Go Daddy Secure Certificate Authority - G2,OU=http://certs.godaddy.com/repository/,O=GoDaddy.com\\\\, Inc.,L=Scottsdale,ST=Arizona,C=US’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 301 \n",
            "Location: http://s3.amazonaws.com/text-datasets/aclImdb.zip [following]\n",
            "--2020-01-23 14:24:11--  http://s3.amazonaws.com/text-datasets/aclImdb.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.230.13\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.230.13|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60711700 (58M) [application/zip]\n",
            "Saving to: ‘0tIo’\n",
            "\n",
            "0tIo                100%[===================>]  57.90M  34.2MB/s    in 1.7s    \n",
            "\n",
            "2020-01-23 14:24:13 (34.2 MB/s) - ‘0tIo’ saved [60711700/60711700]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thGWbdrNLT8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q 0tIo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K701fgeWzB5R",
        "colab_type": "text"
      },
      "source": [
        "# Read the IMDB Data and append labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQQRfVtxLnS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_dir = '/content/aclImdb'\n",
        "train_dir = os.path.join(imdb_dir, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "  dir_name = os.path.join(train_dir, label_type)\n",
        "  for fname in os.listdir(dir_name):\n",
        "    #print(fname)\n",
        "    if fname[-4:] == '.txt':\n",
        "      #print('opening file', fname)\n",
        "      f = open(os.path.join(dir_name, fname))\n",
        "      texts.append(f.read())\n",
        "      f.close()\n",
        "      if label_type == 'neg':\n",
        "        labels.append(0)\n",
        "      else:\n",
        "        labels.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3OwaU8tzMDS",
        "colab_type": "text"
      },
      "source": [
        "# Print the Length of the texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7orZNf4r5cz6",
        "colab_type": "code",
        "outputId": "a9fdcdc2-8937-4ffd-e0f0-8565417e1387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(texts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMrtToDz5fzU",
        "colab_type": "code",
        "outputId": "657e50b9-c556-46e7-cbe0-eacabce37c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "maxlen = 100                  # Define the maximum length of each record \n",
        "training_samples = 8000       # Define the number of samples to be taken for training\n",
        "validation_samples = 10000    # Define number of validation samples. In this we will see that even less number of training samples than validation data also perform not very bad \n",
        "max_words = 10000             # Creates a tokenizer, configured to only take into account the 10,000 most common words\n",
        "\n",
        "\n",
        "# Create Tokenizer , Fit it to the Texts and create a sequence of texts from the tokenizer \n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "# Create a dictionary of the word and respective numeric index value \n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "# Define the sequence with the numeric indexes \n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "# variable for labels\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# Shuffle the indices as the data are normally in group for each label \n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "# Segreegate data for training and validation \n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 88582 unique tokens.\n",
            "Shape of data tensor: (25000, 100)\n",
            "Shape of label tensor: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApuUJ73R621f",
        "colab_type": "text"
      },
      "source": [
        "# Open Question : \n",
        "What are those 10,000 words that the model will select out of entire corpus ? is it the first 10k or at random ?\n",
        "\n",
        "Answer : We believe only the Top 10k words will be selected \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLxlohYc3lA2",
        "colab_type": "text"
      },
      "source": [
        "# Download the Glove model . \n",
        "Here we are downloading the Glove6B model as our environment may not support heavier models than this due to memory constraints "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBdzSAxl5xNV",
        "colab_type": "code",
        "outputId": "4d71b6c7-341a-4833-cf61-1c17ec819c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-23 14:47:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-01-23 14:47:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-01-23 14:47:27--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.07MB/s    in 6m 27s  \n",
            "\n",
            "2020-01-23 14:53:54 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx35i3wG6Ch-",
        "colab_type": "code",
        "outputId": "34f37074-0442-40a7-eae8-f88abdce80df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbXwoeDA337T",
        "colab_type": "text"
      },
      "source": [
        "We will use the glove model for 100 dimension . We can use heavier models but due to memory constraints we are using this one "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tit5ZmAa7kBE",
        "colab_type": "text"
      },
      "source": [
        "# Read the embedding file and load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkq4BSOh8i_q",
        "colab_type": "code",
        "outputId": "4f9fc642-44b2-42da-cb3a-6827d0ea90d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "glove_dir = '/content'\n",
        "embeddings_index = {}\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_file_name = 'glove.6B.100d.txt'\n",
        "\n",
        "f = open(os.path.join(glove_dir, embedding_file_name ))\n",
        "for line in f:\n",
        "  values = line.split()\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:], dtype='float32')\n",
        "  embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNBxoMiS77DZ",
        "colab_type": "text"
      },
      "source": [
        "# Let's display some to see how it looks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFmGdRjb81P1",
        "colab_type": "code",
        "outputId": "91c740d8-6bae-4cba-cf71-d92984fa14ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(list(embeddings_index.keys())[0:100])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\", 'for', '-', 'that', 'on', 'is', 'was', 'said', 'with', 'he', 'as', 'it', 'by', 'at', '(', ')', 'from', 'his', \"''\", '``', 'an', 'be', 'has', 'are', 'have', 'but', 'were', 'not', 'this', 'who', 'they', 'had', 'i', 'which', 'will', 'their', ':', 'or', 'its', 'one', 'after', 'new', 'been', 'also', 'we', 'would', 'two', 'more', \"'\", 'first', 'about', 'up', 'when', 'year', 'there', 'all', '--', 'out', 'she', 'other', 'people', \"n't\", 'her', 'percent', 'than', 'over', 'into', 'last', 'some', 'government', 'time', '$', 'you', 'years', 'if', 'no', 'world', 'can', 'three', 'do', ';', 'president', 'only', 'state', 'million', 'could', 'us', 'most', '_', 'against', 'u.s.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L_iL1EN7-4h",
        "colab_type": "text"
      },
      "source": [
        "# Steps\n",
        "1. Define a  blank Embedding_matrix\n",
        "2. Update Embedding matrix by reading sequentially using the Embedding Index "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vc5kuDW8-9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector   # Words not found in the embedding index will be all zeros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0XiaMRC85fB",
        "colab_type": "text"
      },
      "source": [
        "# Define a Sequential model \n",
        "The Model consisits of 2 fully connected layers . This is one of the simple layers used as the intention here is to understand how word embedding works and not to go deeep models to improve the accuracy of the model. We will look into model training and performance improvement later\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6qg35_D9HLr",
        "colab_type": "code",
        "outputId": "72903c27-5f65-48e0-c8a5-4a58e10f7b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 100, 100)          1000000   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                320032    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,320,065\n",
            "Trainable params: 1,320,065\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QPbiuI59iuf",
        "colab_type": "text"
      },
      "source": [
        "1. Set the weights to the Embedding matrix \n",
        "2.  freeze the Embedding layer (set its trainable attribute to False) as we are using a pretrained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSUOohBQ9J3r",
        "colab_type": "code",
        "outputId": "92327784-2fb9-4a47-f9e0-83abcfd34c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "\n",
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jzwr679CSBl",
        "colab_type": "text"
      },
      "source": [
        "# Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLdONR1n9MgG",
        "colab_type": "code",
        "outputId": "f9c83cdd-7833-42de-aa2d-2160ae818873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val)\n",
        "                    )\n",
        "\n",
        "model.save_weights('pre_trained_glove_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 8000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "8000/8000 [==============================] - 3s 368us/step - loss: 0.7117 - acc: 0.5649 - val_loss: 0.6617 - val_acc: 0.5961\n",
            "Epoch 2/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 0.5946 - acc: 0.6835 - val_loss: 0.6133 - val_acc: 0.6540\n",
            "Epoch 3/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.4971 - acc: 0.7659 - val_loss: 0.5930 - val_acc: 0.6910\n",
            "Epoch 4/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.4145 - acc: 0.8151 - val_loss: 0.5921 - val_acc: 0.7077\n",
            "Epoch 5/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.3715 - acc: 0.8375 - val_loss: 0.6849 - val_acc: 0.6712\n",
            "Epoch 6/100\n",
            "8000/8000 [==============================] - 1s 146us/step - loss: 0.3074 - acc: 0.8706 - val_loss: 0.7510 - val_acc: 0.6816\n",
            "Epoch 7/100\n",
            "8000/8000 [==============================] - 1s 149us/step - loss: 0.2584 - acc: 0.8931 - val_loss: 0.7071 - val_acc: 0.6922\n",
            "Epoch 8/100\n",
            "8000/8000 [==============================] - 1s 151us/step - loss: 0.2085 - acc: 0.9190 - val_loss: 0.8452 - val_acc: 0.6727\n",
            "Epoch 9/100\n",
            "8000/8000 [==============================] - 1s 146us/step - loss: 0.1687 - acc: 0.9361 - val_loss: 0.8973 - val_acc: 0.6870\n",
            "Epoch 10/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 0.1261 - acc: 0.9526 - val_loss: 1.2000 - val_acc: 0.6514\n",
            "Epoch 11/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0998 - acc: 0.9661 - val_loss: 0.9474 - val_acc: 0.6970\n",
            "Epoch 12/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0825 - acc: 0.9743 - val_loss: 1.1108 - val_acc: 0.6854\n",
            "Epoch 13/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0565 - acc: 0.9828 - val_loss: 1.1215 - val_acc: 0.6873\n",
            "Epoch 14/100\n",
            "8000/8000 [==============================] - 1s 167us/step - loss: 0.0461 - acc: 0.9865 - val_loss: 1.1700 - val_acc: 0.6821\n",
            "Epoch 15/100\n",
            "8000/8000 [==============================] - 1s 148us/step - loss: 0.0397 - acc: 0.9882 - val_loss: 1.6142 - val_acc: 0.6617\n",
            "Epoch 16/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0317 - acc: 0.9888 - val_loss: 1.3396 - val_acc: 0.6868\n",
            "Epoch 17/100\n",
            "8000/8000 [==============================] - 1s 146us/step - loss: 0.0339 - acc: 0.9897 - val_loss: 1.4126 - val_acc: 0.6892\n",
            "Epoch 18/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0155 - acc: 0.9941 - val_loss: 1.4815 - val_acc: 0.6799\n",
            "Epoch 19/100\n",
            "8000/8000 [==============================] - 1s 144us/step - loss: 0.0244 - acc: 0.9924 - val_loss: 2.2281 - val_acc: 0.6453\n",
            "Epoch 20/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 0.0197 - acc: 0.9932 - val_loss: 1.6203 - val_acc: 0.6821\n",
            "Epoch 21/100\n",
            "8000/8000 [==============================] - 1s 146us/step - loss: 0.0245 - acc: 0.9928 - val_loss: 1.6800 - val_acc: 0.6808\n",
            "Epoch 22/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0205 - acc: 0.9941 - val_loss: 1.7229 - val_acc: 0.6816\n",
            "Epoch 23/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 0.0171 - acc: 0.9944 - val_loss: 1.8473 - val_acc: 0.6742\n",
            "Epoch 24/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0219 - acc: 0.9929 - val_loss: 1.8300 - val_acc: 0.6841\n",
            "Epoch 25/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0190 - acc: 0.9944 - val_loss: 1.8827 - val_acc: 0.6818\n",
            "Epoch 26/100\n",
            "8000/8000 [==============================] - 1s 146us/step - loss: 0.0119 - acc: 0.9955 - val_loss: 1.7668 - val_acc: 0.6828\n",
            "Epoch 27/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 0.0097 - acc: 0.9969 - val_loss: 1.9880 - val_acc: 0.6823\n",
            "Epoch 28/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0091 - acc: 0.9969 - val_loss: 3.1461 - val_acc: 0.6240\n",
            "Epoch 29/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 0.0151 - acc: 0.9952 - val_loss: 1.9633 - val_acc: 0.6829\n",
            "Epoch 30/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0069 - acc: 0.9973 - val_loss: 2.0416 - val_acc: 0.6878\n",
            "Epoch 31/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 0.0080 - acc: 0.9971 - val_loss: 2.1082 - val_acc: 0.6850\n",
            "Epoch 32/100\n",
            "8000/8000 [==============================] - 1s 166us/step - loss: 0.0133 - acc: 0.9951 - val_loss: 2.0744 - val_acc: 0.6821\n",
            "Epoch 33/100\n",
            "8000/8000 [==============================] - 1s 144us/step - loss: 0.0088 - acc: 0.9966 - val_loss: 2.0510 - val_acc: 0.6794\n",
            "Epoch 34/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0048 - acc: 0.9980 - val_loss: 2.1627 - val_acc: 0.6822\n",
            "Epoch 35/100\n",
            "8000/8000 [==============================] - 1s 142us/step - loss: 0.0039 - acc: 0.9981 - val_loss: 2.1904 - val_acc: 0.6838\n",
            "Epoch 36/100\n",
            "8000/8000 [==============================] - 1s 144us/step - loss: 0.0059 - acc: 0.9978 - val_loss: 2.2115 - val_acc: 0.6829\n",
            "Epoch 37/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 0.0076 - acc: 0.9973 - val_loss: 2.2040 - val_acc: 0.6801\n",
            "Epoch 38/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0099 - acc: 0.9973 - val_loss: 2.2763 - val_acc: 0.6824\n",
            "Epoch 39/100\n",
            "8000/8000 [==============================] - 1s 169us/step - loss: 0.0068 - acc: 0.9974 - val_loss: 2.3070 - val_acc: 0.6809\n",
            "Epoch 40/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0032 - acc: 0.9988 - val_loss: 2.2666 - val_acc: 0.6821\n",
            "Epoch 41/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 0.0064 - acc: 0.9976 - val_loss: 2.3757 - val_acc: 0.6828\n",
            "Epoch 42/100\n",
            "8000/8000 [==============================] - 1s 142us/step - loss: 0.0055 - acc: 0.9983 - val_loss: 2.4679 - val_acc: 0.6773\n",
            "Epoch 43/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0012 - acc: 0.9992 - val_loss: 2.4134 - val_acc: 0.6786\n",
            "Epoch 44/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0063 - acc: 0.9973 - val_loss: 2.3969 - val_acc: 0.6810\n",
            "Epoch 45/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0069 - acc: 0.9984 - val_loss: 2.4192 - val_acc: 0.6791\n",
            "Epoch 46/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 2.4400 - val_acc: 0.6786\n",
            "Epoch 47/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 2.4633 - val_acc: 0.6809\n",
            "Epoch 48/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 0.0049 - acc: 0.9988 - val_loss: 2.4532 - val_acc: 0.6803\n",
            "Epoch 49/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 0.0054 - acc: 0.9979 - val_loss: 2.7227 - val_acc: 0.6733\n",
            "Epoch 50/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 2.5198 - val_acc: 0.6851\n",
            "Epoch 51/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0025 - acc: 0.9990 - val_loss: 3.3357 - val_acc: 0.6512\n",
            "Epoch 52/100\n",
            "8000/8000 [==============================] - 1s 162us/step - loss: 0.0069 - acc: 0.9983 - val_loss: 2.6006 - val_acc: 0.6799\n",
            "Epoch 53/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 2.6545 - val_acc: 0.6796\n",
            "Epoch 54/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0028 - acc: 0.9989 - val_loss: 2.6466 - val_acc: 0.6871\n",
            "Epoch 55/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 0.0015 - acc: 0.9994 - val_loss: 2.6521 - val_acc: 0.6838\n",
            "Epoch 56/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 0.0013 - acc: 0.9994 - val_loss: 2.6635 - val_acc: 0.6812\n",
            "Epoch 57/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0030 - acc: 0.9992 - val_loss: 2.7062 - val_acc: 0.6853\n",
            "Epoch 58/100\n",
            "8000/8000 [==============================] - 1s 135us/step - loss: 0.0012 - acc: 0.9994 - val_loss: 2.6864 - val_acc: 0.6867\n",
            "Epoch 59/100\n",
            "8000/8000 [==============================] - 1s 142us/step - loss: 0.0012 - acc: 0.9995 - val_loss: 2.7857 - val_acc: 0.6810\n",
            "Epoch 60/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0057 - acc: 0.9988 - val_loss: 2.7716 - val_acc: 0.6830\n",
            "Epoch 61/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 2.8266 - val_acc: 0.6861\n",
            "Epoch 62/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 2.8167 - val_acc: 0.6850\n",
            "Epoch 63/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0017 - acc: 0.9998 - val_loss: 2.8485 - val_acc: 0.6845\n",
            "Epoch 64/100\n",
            "8000/8000 [==============================] - 1s 144us/step - loss: 5.8469e-04 - acc: 0.9996 - val_loss: 2.8376 - val_acc: 0.6818\n",
            "Epoch 65/100\n",
            "8000/8000 [==============================] - 1s 142us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 2.8551 - val_acc: 0.6787\n",
            "Epoch 66/100\n",
            "8000/8000 [==============================] - 1s 153us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 2.8387 - val_acc: 0.6815\n",
            "Epoch 67/100\n",
            "8000/8000 [==============================] - 1s 155us/step - loss: 0.0021 - acc: 0.9991 - val_loss: 2.9458 - val_acc: 0.6773\n",
            "Epoch 68/100\n",
            "8000/8000 [==============================] - 1s 148us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 2.9035 - val_acc: 0.6864\n",
            "Epoch 69/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 6.2708e-04 - acc: 0.9999 - val_loss: 2.9102 - val_acc: 0.6821\n",
            "Epoch 70/100\n",
            "8000/8000 [==============================] - 1s 147us/step - loss: 0.0034 - acc: 0.9994 - val_loss: 2.9171 - val_acc: 0.6823\n",
            "Epoch 71/100\n",
            "8000/8000 [==============================] - 1s 146us/step - loss: 5.4609e-04 - acc: 0.9998 - val_loss: 2.9494 - val_acc: 0.6844\n",
            "Epoch 72/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 0.0020 - acc: 0.9996 - val_loss: 2.8928 - val_acc: 0.6807\n",
            "Epoch 73/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 2.9171 - val_acc: 0.6823\n",
            "Epoch 74/100\n",
            "8000/8000 [==============================] - 1s 142us/step - loss: 2.6416e-04 - acc: 0.9999 - val_loss: 2.9460 - val_acc: 0.6786\n",
            "Epoch 75/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 3.0711 - val_acc: 0.6737\n",
            "Epoch 76/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 8.3233e-04 - acc: 0.9999 - val_loss: 3.0049 - val_acc: 0.6816\n",
            "Epoch 77/100\n",
            "8000/8000 [==============================] - 1s 150us/step - loss: 9.2991e-05 - acc: 1.0000 - val_loss: 2.9729 - val_acc: 0.6845\n",
            "Epoch 78/100\n",
            "8000/8000 [==============================] - 1s 152us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 3.0218 - val_acc: 0.6847\n",
            "Epoch 79/100\n",
            "8000/8000 [==============================] - 1s 148us/step - loss: 9.1540e-05 - acc: 1.0000 - val_loss: 3.1206 - val_acc: 0.6862\n",
            "Epoch 80/100\n",
            "8000/8000 [==============================] - 1s 143us/step - loss: 0.0014 - acc: 0.9994 - val_loss: 3.1241 - val_acc: 0.6765\n",
            "Epoch 81/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 6.6632e-04 - acc: 0.9998 - val_loss: 3.0942 - val_acc: 0.6818\n",
            "Epoch 82/100\n",
            "8000/8000 [==============================] - 1s 152us/step - loss: 2.8792e-04 - acc: 1.0000 - val_loss: 3.0790 - val_acc: 0.6843\n",
            "Epoch 83/100\n",
            "8000/8000 [==============================] - 1s 146us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 3.1052 - val_acc: 0.6804\n",
            "Epoch 84/100\n",
            "8000/8000 [==============================] - 1s 177us/step - loss: 1.1912e-04 - acc: 1.0000 - val_loss: 3.7102 - val_acc: 0.6517\n",
            "Epoch 85/100\n",
            "8000/8000 [==============================] - 1s 153us/step - loss: 7.0308e-04 - acc: 0.9998 - val_loss: 3.1356 - val_acc: 0.6808\n",
            "Epoch 86/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 0.0013 - acc: 0.9995 - val_loss: 3.0778 - val_acc: 0.6780\n",
            "Epoch 87/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 2.9133e-04 - acc: 1.0000 - val_loss: 3.1091 - val_acc: 0.6796\n",
            "Epoch 88/100\n",
            "8000/8000 [==============================] - 1s 147us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 3.0867 - val_acc: 0.6764\n",
            "Epoch 89/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 4.9641e-04 - acc: 0.9999 - val_loss: 3.1796 - val_acc: 0.6802\n",
            "Epoch 90/100\n",
            "8000/8000 [==============================] - 1s 145us/step - loss: 6.3069e-04 - acc: 0.9999 - val_loss: 3.2869 - val_acc: 0.6810\n",
            "Epoch 91/100\n",
            "8000/8000 [==============================] - 1s 158us/step - loss: 1.0905e-04 - acc: 1.0000 - val_loss: 3.2066 - val_acc: 0.6828\n",
            "Epoch 92/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 8.4157e-05 - acc: 1.0000 - val_loss: 3.2200 - val_acc: 0.6801\n",
            "Epoch 93/100\n",
            "8000/8000 [==============================] - 1s 141us/step - loss: 4.8338e-04 - acc: 0.9999 - val_loss: 3.2460 - val_acc: 0.6825\n",
            "Epoch 94/100\n",
            "8000/8000 [==============================] - 1s 140us/step - loss: 9.8611e-05 - acc: 1.0000 - val_loss: 3.2720 - val_acc: 0.6826\n",
            "Epoch 95/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 1.4072e-04 - acc: 1.0000 - val_loss: 3.2231 - val_acc: 0.6830\n",
            "Epoch 96/100\n",
            "8000/8000 [==============================] - 1s 139us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 3.2738 - val_acc: 0.6818\n",
            "Epoch 97/100\n",
            "8000/8000 [==============================] - 1s 138us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 3.2393 - val_acc: 0.6851\n",
            "Epoch 98/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 8.2330e-05 - acc: 1.0000 - val_loss: 3.2805 - val_acc: 0.6867\n",
            "Epoch 99/100\n",
            "8000/8000 [==============================] - 1s 136us/step - loss: 7.7560e-04 - acc: 0.9999 - val_loss: 3.3028 - val_acc: 0.6778\n",
            "Epoch 100/100\n",
            "8000/8000 [==============================] - 1s 137us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 3.2920 - val_acc: 0.6824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uj9gmyKCanv",
        "colab_type": "text"
      },
      "source": [
        "# Plot the Output to see the performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b93br3b9TMp",
        "colab_type": "code",
        "outputId": "9c5cf1d7-153b-4d45-b3fe-4b953256ad83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzjmXJjygO+dcmvCA7pxzaeL/A6z0dQtejObaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alpYbOhA9X7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}